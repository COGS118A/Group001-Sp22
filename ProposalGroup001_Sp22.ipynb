{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7MC8HMGROWD"
      },
      "source": [
        "# COGS 118A- Project Proposal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOBJOXAZROWF"
      },
      "source": [
        "# Project Description\n",
        "\n",
        "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
        "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
        "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
        "\n",
        "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
        "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
        "- You will be writing a report describing and discussing these accomplishments\n",
        "\n",
        "\n",
        "Feel free to delete this description section when you hand in your proposal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9igVLA46ROWG"
      },
      "source": [
        "### Peer Review\n",
        "\n",
        "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
        "\n",
        "Both the project proposal and project checkpoint will have peer review."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVA4oOQDROWG"
      },
      "source": [
        "# Names\n",
        "\n",
        "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
        "\n",
        "- Alan Cao (A16160244)\n",
        "- Connie Chang (A16651609)\n",
        "- Helen Zhao\n",
        "- Shawn Kim (A15785021)\n",
        "- Robert Aispuro (A12086294)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WClFIXsZROWH"
      },
      "source": [
        "# Abstract \n",
        "\n",
        "Heart disease is a common cause of death in the United States. There are a variety of factors that contribute to the likelihood of heart disease. However, not all variables increase the chance of cardiovascular disease in the same amount. In this paper we will create a predictive machine learning model that is effective in detecting heart disease by using data originating from the Center of Disease and Control and Prevention (CDC). Factors such as smoking, alcohol use, or stroke history. We will be running a logistic regression as well as a random decision forest. By analyzing this data set, we aim to better prevent cardiovascular disease and thus remove heart disease as a leading cause of death in the United States. Performance will be measured by if the factors directly or indirectly influnce heart disease. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qAtND-DROWH"
      },
      "source": [
        "# Background"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the CDC, heart disease is the leading cause of death in the United States. However, the prediction of cardiovascular disease still remains as a challenge in the area of clinical data analysis despite the continuous growth of science and technology. It goes without saying that identifying coronary heart disease during the early stages is beneficial in minimizing the development of the disease and thus preventing the need for treatment. Therefore it is extremely important to continue to develop more effective ways of more accurately identifying risk factors that play a role in predicting heart disease. \n",
        "\n",
        "Previous research has shown that traditional cardiovascular risk factors are nearly equally valuable in assessing the likelihood of someone developing CHD as a looking at a genetic test. The risk factors listed include blood pressure, cholesterol levels, diabetes, and smoking status<a name=\"Wilson\"></a>[<sup>[1]</sup>](#Wilsonnote). Even though the genetic risk scores doesn't seem to necessarily add more predictive value, it is still necessary to develop a model that uses either traditional or genetic variables to more accurately predict CHD. Another article states that there is no clear difference in the effectiveness of using either categorical or continuous values of those risk factors in the prediction. Furthermore, the article discusses the limitations of their findings because of the exclusion of certain candidate variables. Such variables include family history of CHD, fibrinogen, exercise, and body mass index (BMI)<a name=\"UTSouth\"></a>[<sup>[2]</sup>](#UTSouthnote). Therefore, further research needs to be done on the predictive value of these excluded variables as well as the effectiveness of having a mixture of discrete and continuous variables in the predictive model.\n",
        "\n",
        "Due to the nature of heart disease risk factors to be complex and to depend largely on environmental factors, it is important to develop a model that is able to take these into consideration. Machine learning algorithms have been used in the past to detect and address the severity of the heart disease of patients. In terms of accuracy, random forest, support vector machine, deep learning, VOTE, and HRFLM are some of the best classification methods<a name=\"Mohan\"></a>[<sup>[3]</sup>](#Mohannote). Although this paper has analyzed the effectiveness of different machine learning models, further extension is needed to use real-world datasets on these models as the paper only used simulations and theoretical approaches. "
      ],
      "metadata": {
        "id": "xUnhPuwdW1IN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ7iw7OfROWI"
      },
      "source": [
        "# Problem Statement\n",
        "\n",
        "\n",
        "\n",
        "The problem we are trying to solve is to better predict which factors influence cardiovascular disease whether that be indirectly or directly. We are going to run a logistical regression on the variables. We will be using a group of techniques in order to balance the class distribution for our dataset since it has a skewed class distribution. By classifing our variables in a binary \"Yes\" or \"No\" format, we can predict which factors play a role in heart disease. We will run this alongside our whole dataset in order to replicate it with over 400,000 other patients in order to see if our model is accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPDW6gFxROWI"
      },
      "source": [
        "# Data\n",
        "\n",
        "Link/Reference: https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease\n",
        "\n",
        "The dataset includes 18 variables and just over 300,000 observations. An observation consists of attributes such as a person's BMI, whether they smoked, their age, sex, and whether they contracted a heart disease. Some crucial variables are sex represented by \"Male\" and \"Female\" and age which is represented by an interval. Some boolean values are represented by \"Yes\" or \"No\". We will need to transform these values into a numerical format (1s and 0s) in order to process them. We also have categorical variables like General Health which we can convert numerically with one hot encoding. Given these variables and which observations had heart disease, we will be able to predict how attributes contribute to cardivascular disease the most and take steps in order to prevent disease."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw14M8c7ROWJ"
      },
      "source": [
        "# Proposed Solution\n",
        "\n",
        "Our team will be running a logistic regression and a random decision forest. Logistic regression models the probability of discrete outcomes and is useful for classification tasks. We will be classifying the 18 variables to 'yes' or 'no' to predict the major factors that influence heart disease. The other algorithm we will be running is random decision fores, which is made up of many individual decision trees. Each individual tree in the random forest represents a variable and outputs a class prediction. The variable that end up with the most votes will be our model’s prediction, the most significant factor that leads to heart disease."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc4PxMTJROWK"
      },
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "Our team will use precision as our evaluation metric. Because heart disease is a condition that endangers lives, using precision would reduce false negatives, decreasing the chance of a patient with heart disease to have a negative result. However, increasing precision would decrease recall, increasing the number of false positives (the chance a patient without heart disease has a positive result). Precision is calculated by dividing the sum of the True Positives by the sum of the Predicted Conditions that are positive (true positives + false positives)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5zY4nQHROWK"
      },
      "source": [
        "# Ethics & Privacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxa4EId_ROWK"
      },
      "source": [
        "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
        "\n",
        "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
        "\n",
        "Consider a tool to help you address the potential issues such as https://deon.drivendata.org"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset utilized in this project relates to patient’s medical history with heart disease. Therefore, it is important that there is no way to tie a particular data point to any one individual, so it is anonymized. In terms of bias, one thing we do want to watch out for is to make sure that all the states in United States are represented in the dataset as to prevent bias, such as how differences in lifestyles in different states could impact risk for heart disease. To get a representative figure for each state, we consider the states as a whole, taking into account all of the regions as one. In order to address these concerns in bias, we have used a dataset from Kaggle that was originally from the CDC as part of the Behavioral Risk Factor Surveillance System (BRFSS). CDC states that BRFSS  collects data in all 50 states as well as the District of Columbia and three U.S. territories. The dataset also includes over 300,000 survey responses. As a result we can ensuring that a large majority of the regions in the United States could be represented in this study.\n",
        "\n",
        "Overall, the data we use for this project has been collected fairly and passes our privacy considerations. In terms of intent, the purpose of this project is to discover possible correlations between participant lifestyles and risk for heart disease, without any goal to implicate or harm any individuals. Due to the fact that our data is anonymized, this project cannot be used to single out or direct harm to an individual. At its base, this project just offers an unbiased study on a prediction model for heart disease. "
      ],
      "metadata": {
        "id": "gr5rYmvktSu3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7IBXVIgROWK"
      },
      "source": [
        "# Team Expectations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIWx1klfROWL"
      },
      "source": [
        "* *Fair amount of work distributed across each member of the group*\n",
        "* *Make sure everyone is in the loop about what's happening*\n",
        "* *If confused, reach out for help*\n",
        "* *Try to get things done early*\n",
        "* *COMMUNICATE! Communication is key and can solve alot of problems from even occuring*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0bcVvnnROWL"
      },
      "source": [
        "# Project Timeline Proposal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fru2qdYLROWL"
      },
      "source": [
        "\n",
        "| Meeting Date  | Meeting Time| Discuss at Meeting  | IGNORE |\n",
        "|---|---|---|---|\n",
        "| 4/28  |  1 PM |Determine best form of communication; Discuss and decide on final project methods;| \n",
        "| 4/29  |  10 AM |  Peer reviews of proposals due. Each group will get ~5 peer reviews which can help you make your project better. In addition, each of your group members will probably have reviewed different projects, so you should discuss among yourselves what you saw during that time. | \n",
        "| 5/1 | 10 AM  | Work on Checkpoint and schedule out time for midterms and everyone else|\n",
        "| 5/7  | 6 PM  | EDA and work on checkpoint continued. Fix any mistakes as well as talk to the TA|\n",
        "|5/10  | 12 PM  | Finalize wrangling/EDA; Complete checkpoint and any missing work |\n",
        "| 5/13  | 12 PM  |Checkpoint due. We want to see that we've got at least a good chunk of your data processed, done some EDA, have at least a clear idea of what the next steps are (what features/algorithms/metrics will be used).  Ideally we should see some pilot results. Another round of peer review will take place.|\n",
        "| 5/20  | Before 11:59 PM  |Checkpoint peer reviews due  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic9Cf6CCROWM"
      },
      "source": [
        "# Footnotes\n",
        "\n",
        "<a name=\"Wilsonnote\"></a>1.[^](#Wilson): Wilson, P. W. F., D’Agostino, R. B., Levy, D., Belanger, A. M., Silbershatz, H., &amp; Kannel, W. B. (1998, May 12). Prediction of coronary heart disease using risk factor categories. Circulation. Retrieved April 24, 2022, from https://www.ahajournals.org/doi/10.1161/01.cir.97.18.1837 \n",
        "\n",
        "<a name=\"UTSouthnote\"></a>2.[^](#UTSouth): Traditional risk factors predict heart disease about as well as sophisticated genetic test, study suggests. UT Southwestern Medical Center. (2020, February 18). Retrieved April 24, 2022, from https://www.utsouthwestern.edu/newsroom/articles/year-2020/predicting-heart-disease.html#:~:text=18%2C%202020%20%E2%80%93%20Traditional%20cardiovascular%20risk,that%20surveys%20millions%20of%20different \n",
        "\n",
        "<a name=\"Mohannote\"></a>3.[^](#Mohan): Mohan, S., Thirumalai, C., &amp; Srivastava, G. (2019, June 19). Effective heart disease prediction using hybrid machine learning techniques. IEEE Xplore. Retrieved April 24, 2022, from https://ieeexplore.ieee.org/abstract/document/8740989#citations "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "ProposalGroup001-Sp22.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
